{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural networks with NALU as proposed by Trask et al. in their paper: https://arxiv.org/abs/1808.00508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the main equations that govern the supremacy of NALU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/RhSvJby/NAC-NALU.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from NAC import NAC\n",
    "from NALU import NALU\n",
    "from torch.optim import RMSprop, Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments (for Synthetic Arithmetic Tasks (refer Appendix B in the paper))\n",
    "\n",
    "- Generate sample data\n",
    "- Enlist the arithmetic operations\n",
    "- Train shallow networks w.r.t the arithmetic operations\n",
    "- Evaluate the network implemented with NALU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "\n",
    "Generate 2-D and 1-D data-points (1-D for square and square-roots) sampled from a uniform distribution within the range of [*min_val*, *max_val*] for the arithmetic operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(min_val, max_val, observations, op):\n",
    "    data = np.random.uniform(min_val, max_val, size=(observations, 2))\n",
    "    if op == '+':\n",
    "        target = data[:, 0] + data[:, 1]\n",
    "    elif op == '-':\n",
    "        target = data[:, 0] - data[:, 1]\n",
    "    elif op == '*':\n",
    "        target = data[:, 0] * data[:, 1]\n",
    "    elif op == '/':\n",
    "        target = data[:, 0] / data[:, 1]\n",
    "    elif op == '^2':\n",
    "        data = np.random.uniform(min_val, max_val, size=(observations, 1))\n",
    "        target = data ** 2\n",
    "    elif op == 'sqrt':\n",
    "        data = np.random.uniform(min_val, max_val, size=(observations, 1))\n",
    "        target = np.sqrt(data)\n",
    "    \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enlist the arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = ['+', '-', '*', '/', 'sqrt', '^2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function for training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, X, y, epochs, criterion, optimizer):\n",
    "    # Create tensor from the numpy arrays\n",
    "    X = torch.from_numpy(X)\n",
    "    X = X.float()\n",
    "    y = torch.from_numpy(y)\n",
    "    y = y.float().view(-1, 1)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        # Forward Propagation\n",
    "        y_pred = model(X)\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        # Output logging\n",
    "        if epoch%500 == 0:\n",
    "            print('epoch: ', epoch,' loss: ', loss.item())\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(op, model, validation_data):\n",
    "    # Unpack the data\n",
    "    X_valid, y_valid = validation_data\n",
    "    \n",
    "    # Create tensors\n",
    "    X_valid = torch.from_numpy(X_valid)\n",
    "    X_valid = X_valid.float()\n",
    "    y_valid = torch.from_numpy(y_valid)\n",
    "    y_valid = y_valid.float().view(-1, 1)\n",
    "    \n",
    "    # Sets the all requires_grad to False: https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        preds = (model(X_valid))\n",
    "        # Convert into numpy arrays and flatten them\n",
    "        original = y_valid.cpu().numpy().flatten()\n",
    "        prediction = preds.cpu().numpy().flatten()\n",
    "        # Determine how close the predicitions are to true values (upto three decimal places)\n",
    "        accuracy = np.isclose(prediction, original, rtol=1e-3)\n",
    "        accuracy = accuracy.astype(np.int32).mean()\n",
    "        # Return the accuracy score\n",
    "        return accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train shallow networks w.r.t the arithmetic operations and evaluation\n",
    "> Adam fails miserably with default settings :O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Training the model for [+] -------\n",
      "epoch:  500  loss:  2.474065065383911\n",
      "epoch:  1000  loss:  0.2002781629562378\n",
      "epoch:  1500  loss:  0.01778424344956875\n",
      "epoch:  2000  loss:  0.0016054622828960419\n",
      "epoch:  2500  loss:  0.00014577888941857964\n",
      "epoch:  3000  loss:  1.3271685020299628e-05\n",
      "epoch:  3500  loss:  1.209169568028301e-06\n",
      "epoch:  4000  loss:  1.1231373520104171e-07\n",
      "epoch:  4500  loss:  1.1934092825072184e-08\n",
      "epoch:  5000  loss:  2.0231571973283735e-09\n",
      "epoch:  5500  loss:  7.221577225102749e-10\n",
      "epoch:  6000  loss:  4.369590800301637e-10\n",
      "epoch:  6500  loss:  3.7942810005020533e-10\n",
      "epoch:  7000  loss:  1.8777208954379176e-10\n",
      "epoch:  7500  loss:  1.8777208954379176e-10\n",
      "epoch:  8000  loss:  1.8777208954379176e-10\n",
      "epoch:  8500  loss:  1.8777208954379176e-10\n",
      "epoch:  9000  loss:  1.5406258213612745e-10\n",
      "epoch:  9500  loss:  1.5406258213612745e-10\n",
      "epoch:  10000  loss:  8.952629609870755e-11\n",
      "------- Training completed! -------\n",
      "------- Validting the model for [+] -------\n",
      "Validation Accuracy for op[+] 100.0\n",
      "------- Testing the model for [+] -------\n",
      "Test Accuracy for op[+] 100.0\n",
      "------- Training the model for [-] -------\n",
      "epoch:  500  loss:  0.07372027635574341\n",
      "epoch:  1000  loss:  0.015349065884947777\n",
      "epoch:  1500  loss:  0.0016263555735349655\n",
      "epoch:  2000  loss:  0.00014947760791983455\n",
      "epoch:  2500  loss:  1.3694771041627973e-05\n",
      "epoch:  3000  loss:  1.2596751730598044e-06\n",
      "epoch:  3500  loss:  1.1725923343419709e-07\n",
      "epoch:  4000  loss:  1.2154802497832407e-08\n",
      "epoch:  4500  loss:  2.103628160554649e-09\n",
      "epoch:  5000  loss:  8.468903356373403e-10\n",
      "epoch:  5500  loss:  5.060270535928169e-10\n",
      "epoch:  6000  loss:  3.564118444820963e-10\n",
      "epoch:  6500  loss:  2.772120311078652e-10\n",
      "epoch:  7000  loss:  2.3021914929977072e-10\n",
      "epoch:  7500  loss:  1.9550133734114183e-10\n",
      "epoch:  8000  loss:  1.683163053378678e-10\n",
      "epoch:  8500  loss:  1.4501022604918035e-10\n",
      "epoch:  9000  loss:  1.3269067788979072e-10\n",
      "epoch:  9500  loss:  1.1661180354671785e-10\n",
      "epoch:  10000  loss:  1.0690524854251038e-10\n",
      "------- Training completed! -------\n",
      "------- Validting the model for [-] -------\n",
      "Validation Accuracy for op[-] 99.96666666666667\n",
      "------- Testing the model for [-] -------\n",
      "Test Accuracy for op[-] 99.84285714285714\n",
      "------- Training the model for [*] -------\n",
      "epoch:  500  loss:  4638.5224609375\n",
      "epoch:  1000  loss:  343.03765869140625\n",
      "epoch:  1500  loss:  30.51190185546875\n",
      "epoch:  2000  loss:  2.807058572769165\n",
      "epoch:  2500  loss:  0.2608703672885895\n",
      "epoch:  3000  loss:  0.02422931231558323\n",
      "epoch:  3500  loss:  0.002264935290440917\n",
      "epoch:  4000  loss:  0.00020248140208423138\n",
      "epoch:  4500  loss:  1.9452225387794897e-05\n",
      "epoch:  5000  loss:  2.0953782495780615e-06\n",
      "epoch:  5500  loss:  1.0663559635304409e-07\n",
      "epoch:  6000  loss:  1.6302056593531233e-08\n",
      "epoch:  6500  loss:  1.6302056593531233e-08\n",
      "epoch:  7000  loss:  1.6302056593531233e-08\n",
      "epoch:  7500  loss:  1.6302056593531233e-08\n",
      "epoch:  8000  loss:  1.6302056593531233e-08\n",
      "epoch:  8500  loss:  1.6302056593531233e-08\n",
      "epoch:  9000  loss:  1.6302056593531233e-08\n",
      "epoch:  9500  loss:  1.6302056593531233e-08\n",
      "epoch:  10000  loss:  1.6302056593531233e-08\n",
      "------- Training completed! -------\n",
      "------- Validting the model for [*] -------\n",
      "Validation Accuracy for op[*] 100.0\n",
      "------- Testing the model for [*] -------\n",
      "Test Accuracy for op[*] 100.0\n",
      "------- Training the model for [/] -------\n",
      "epoch:  500  loss:  0.009621971286833286\n",
      "epoch:  1000  loss:  0.010448973625898361\n",
      "epoch:  1500  loss:  0.008095836266875267\n",
      "epoch:  2000  loss:  0.007756203878670931\n",
      "epoch:  2500  loss:  0.007563209161162376\n",
      "epoch:  3000  loss:  0.00744168646633625\n",
      "epoch:  3500  loss:  0.0073566134087741375\n",
      "epoch:  4000  loss:  0.007292828522622585\n",
      "epoch:  4500  loss:  0.00724265119060874\n",
      "epoch:  5000  loss:  0.007201764732599258\n",
      "epoch:  5500  loss:  0.007167610805481672\n",
      "epoch:  6000  loss:  0.007138501852750778\n",
      "epoch:  6500  loss:  0.007113339379429817\n",
      "epoch:  7000  loss:  0.007091263774782419\n",
      "epoch:  7500  loss:  0.0070717474445700645\n",
      "epoch:  8000  loss:  0.007054310292005539\n",
      "epoch:  8500  loss:  0.007038624491542578\n",
      "epoch:  9000  loss:  0.0070244260132312775\n",
      "epoch:  9500  loss:  0.007011531852185726\n",
      "epoch:  10000  loss:  0.006999710109084845\n",
      "------- Training completed! -------\n",
      "------- Validting the model for [/] -------\n",
      "Validation Accuracy for op[/] 1.2666666666666666\n",
      "------- Testing the model for [/] -------\n",
      "Test Accuracy for op[/] 0.24285714285714283\n",
      "------- Training the model for [sqrt] -------\n",
      "epoch:  500  loss:  0.08247508108615875\n",
      "epoch:  1000  loss:  0.09830567240715027\n",
      "epoch:  1500  loss:  0.0909683033823967\n",
      "epoch:  2000  loss:  0.09051486849784851\n",
      "epoch:  2500  loss:  0.09026413410902023\n",
      "epoch:  3000  loss:  0.08997546136379242\n",
      "epoch:  3500  loss:  0.08969250321388245\n",
      "epoch:  4000  loss:  0.08941447734832764\n",
      "epoch:  4500  loss:  0.08914130926132202\n",
      "epoch:  5000  loss:  0.0888751819729805\n",
      "epoch:  5500  loss:  0.08861581981182098\n",
      "epoch:  6000  loss:  0.08836417645215988\n",
      "epoch:  6500  loss:  0.08811869472265244\n",
      "epoch:  7000  loss:  0.087882399559021\n",
      "epoch:  7500  loss:  0.0876537412405014\n",
      "epoch:  8000  loss:  0.08743418753147125\n",
      "epoch:  8500  loss:  0.08722139149904251\n",
      "epoch:  9000  loss:  0.08701815456151962\n",
      "epoch:  9500  loss:  0.08682198077440262\n",
      "epoch:  10000  loss:  0.08663422614336014\n",
      "------- Training completed! -------\n",
      "------- Validting the model for [sqrt] -------\n",
      "Validation Accuracy for op[sqrt] 1.0999999999999999\n",
      "------- Testing the model for [sqrt] -------\n",
      "Test Accuracy for op[sqrt] 0.18571428571428572\n",
      "------- Training the model for [^2] -------\n",
      "epoch:  500  loss:  360622.8125\n",
      "epoch:  1000  loss:  359883.15625\n",
      "epoch:  1500  loss:  359802.0625\n",
      "epoch:  2000  loss:  359792.46875\n",
      "epoch:  2500  loss:  359791.3125\n",
      "epoch:  3000  loss:  359791.1875\n",
      "epoch:  3500  loss:  359791.15625\n",
      "epoch:  4000  loss:  359791.15625\n",
      "epoch:  4500  loss:  359791.15625\n",
      "epoch:  5000  loss:  359791.15625\n",
      "epoch:  5500  loss:  359791.15625\n",
      "epoch:  6000  loss:  359791.15625\n",
      "epoch:  6500  loss:  359791.15625\n",
      "epoch:  7000  loss:  359791.15625\n",
      "epoch:  7500  loss:  359791.15625\n",
      "epoch:  8000  loss:  359791.15625\n",
      "epoch:  8500  loss:  359791.15625\n",
      "epoch:  9000  loss:  359791.15625\n",
      "epoch:  9500  loss:  359791.15625\n",
      "epoch:  10000  loss:  359791.15625\n",
      "------- Training completed! -------\n",
      "------- Validting the model for [^2] -------\n",
      "Validation Accuracy for op[^2] 0.0\n",
      "------- Testing the model for [^2] -------\n",
      "Test Accuracy for op[^2] 0.0\n"
     ]
    }
   ],
   "source": [
    "test_scores = {}\n",
    "for op in ops:\n",
    "    # Define the train/validation/test sets\n",
    "    X_train, y_train = generate_data(20, 30, 10000, op)\n",
    "    X_valid, y_valid = generate_data(20, 30, 3000, op)\n",
    "    X_test, y_test = generate_data(10, 40, 7000, op)\n",
    "    \n",
    "    # Define network\n",
    "    if op == '^2':\n",
    "        # A slightly deeper network for the exponentiation: https://github.com/Nilabhra/NALU\n",
    "        model = nn.Sequential(NALU(X_train.shape[1], 2), NALU(2, 1))\n",
    "        # Define the loss for model\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        # Define RMSProp as the optimizer\n",
    "        optimizer = RMSprop(model.parameters())\n",
    "        \n",
    "        # Train the network\n",
    "        print('------- Training the model for [{}] -------'.format(op))\n",
    "        trained_model = train_network(model, X_train, y_train, 10000, criterion, optimizer)\n",
    "        print('------- Training completed! -------')\n",
    "        # Model validation\n",
    "        print('------- Validting the model for [{}] -------'.format(op))\n",
    "        validation_data = (X_valid, y_valid)\n",
    "        print('Validation Accuracy for op[{}] '.format(op) + str(validate_model(op, trained_model, validation_data)))\n",
    "        # Model performance on test data\n",
    "        print('------- Testing the model for [{}] -------'.format(op))\n",
    "        validation_data = (X_test, y_test)\n",
    "        print('Test Accuracy for op[{}] '.format(op) + str(validate_model(op, trained_model, validation_data))) \n",
    "        test_scores['^2'] = validate_model(op, trained_model, validation_data)\n",
    "     \n",
    "    else:\n",
    "        model = NALU(X_train.shape[1], 1)\n",
    "        # Define the loss for model\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        # Define RMSProp as the optimizer\n",
    "        optimizer = RMSprop(model.parameters())\n",
    "\n",
    "        # Train the network\n",
    "        print('------- Training the model for [{}] -------'.format(op))\n",
    "        trained_model = train_network(model, X_train, y_train, 10000, criterion, optimizer)\n",
    "        print('------- Training completed! -------')\n",
    "        # Model validation\n",
    "        print('------- Validting the model for [{}] -------'.format(op))\n",
    "        validation_data = (X_valid, y_valid)\n",
    "        print('Validation Accuracy for op[{}] '.format(op) + str(validate_model(op, trained_model, validation_data)))\n",
    "        # Model performance on test data\n",
    "        print('------- Testing the model for [{}] -------'.format(op))\n",
    "        validation_data = (X_test, y_test)\n",
    "        print('Test Accuracy for op[{}] '.format(op) + str(validate_model(op, trained_model, validation_data))) \n",
    "        test_scores[op] = (validate_model(op, trained_model, validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>99.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/</th>\n",
       "      <td>0.242857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqrt</th>\n",
       "      <td>0.185714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy\n",
       "+     100.000000\n",
       "-      99.842857\n",
       "*     100.000000\n",
       "/       0.242857\n",
       "sqrt    0.185714\n",
       "^2      0.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(test_scores, orient='index', columns=['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance seems to be weird. :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "I am grateful to the following repositories from which I took references: \n",
    "- [NALU by Nilabhra Roy Chowdhury](https://github.com/Nilabhra/NALU/)\n",
    "- [NALU by Valeri](https://github.com/vrxacs/NALU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
